As of 3 17, this project includes a simple UI and navigation script. The navigation script uses the navigation package to move to specified way points. Way points are represented in a dictionary which maps a word to the way point. As of right now, the robot needs to be manually localized withing rviz, but the next steps are to automate localization. Harry is currently experimenting with fiducials for this. The next steps will also include the robot returning to the point where it recieved its instructions. 

The UI was developed using the tkinter package in python. Currently it is a drop down menu which publishes a string referring to a location to topic that the navigation script subscribes to. Ben is currently working on integrating automated speech recognition into the UI. He also working on a way to stop the robot's navigation from the UI. The next phase will likely be that UI can use voice to specify a location. After speech has been integrated, work will begin on integrating entity extraction/semantic parsing to make the UI more robust. 
